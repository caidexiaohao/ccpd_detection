import os, gc
from datetime import datetime
import torch
from ultralytics import YOLO

def release_gpu_memory():
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()

def get_resume_model():
    last_path = "runs/detect/train/weights/last.pt"
    if os.path.exists(last_path):
        print("ğŸ” æ£€æµ‹åˆ°å·²æœ‰è®­ç»ƒè®°å½•ï¼Œå°†ä» last.pt ç»§ç»­è®­ç»ƒ")
        return YOLO(last_path), True
    else:
        print("ğŸ†• åˆå§‹åŒ–æ–°æ¨¡å‹ yolo11n.pt")
        return YOLO("yolo11n.pt"), False

def train_model(model, resume=False):
    try:
        model.train(
            data='ccpd.yaml',
            epochs=100,
            batch=64,
            device='0',
            resume=resume,
            patience=10,
            save_period=10  # æ¯éš” 10 epoch ä¿å­˜ä¸€æ¬¡å¿«ç…§
        )
    except RuntimeError as e:
        if "CUDA out of memory" in str(e):
            print("âš ï¸ æ˜¾å­˜ä¸è¶³ï¼Œè‡ªåŠ¨é™ä½ batch size åˆ° 32")
            release_gpu_memory()
            model.train(data='ccpd.yaml', epochs=100, batch=32, device='0', resume=resume)
        else:
            raise e

def export_model(model):
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    export_name = f"ccpd_export_{timestamp}.onnx"
    success = model.export(format='onnx', filename=export_name)
    print("âœ… å¯¼å‡ºæˆåŠŸï¼š" if success else "âŒ å¯¼å‡ºå¤±è´¥", export_name)

def run_prediction(model):
    result = model.predict(source='test/images', save=True, conf=0.5)
    print("ğŸ“¸ æ¨ç†å®Œæˆï¼Œæ£€æµ‹ç»“æœå·²ä¿å­˜")

# é‡Šæ”¾å†…å­˜ & åŠ è½½æ¨¡å‹


if __name__ == '__main__':
    release_gpu_memory()
    model, resume_flag = get_resume_model()
    train_model(model, resume_flag)
    export_model(model)
    run_prediction(model)
